{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting various things for end of grant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import gcat\n",
    "import paramiko\n",
    "import json\n",
    "from IPython import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from curation_common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from htsworkflow.submission.encoded import Document\n",
    "from htsworkflow.submission.aws_submission import run_aws_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = ENCODED('www.encodeproject.org')\n",
    "server.load_netrc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spreadsheet_name = 'ENCODE Submission for Y4Q5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to send ATAC Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/documents/0fc44318-b802-474e-8199-f3b6d708eb6f/\n"
     ]
    }
   ],
   "source": [
    "atac_uuid = '0fc44318-b802-474e-8199-f3b6d708eb6f'\n",
    "atac = Document(os.path.expanduser('~/proj/encode3-curation/Wold_Lab_ATAC_Seq_protocol_December_2016.pdf'),\n",
    "                'general protocol',\n",
    "                'ATAC-Seq experiment protocol for Wold lab',\n",
    "                )\n",
    "body = atac.create_if_needed(server, atac_uuid)\n",
    "print(body['@id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sheet = gcat.get_file(spreadsheet_name, fmt='pandas_excel')\n",
    "annotations = sheet.parse('Annotations', header=0)\n",
    "created = server.post_sheet('/annotations/', annotations, verbose=True, dry_run=True)\n",
    "print(len(created))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if created:\n",
    "    annotations.to_excel('/tmp/annotations.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "sheet = gcat.get_file(spreadsheet_name, fmt='pandas_excel')\n",
    "files = sheet.parse('Files', header=0)\n",
    "created = server.post_sheet('/files/', files, verbose=True, dry_run=True)\n",
    "print(len(created))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fix messed up files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fix_files(files, dry_run=True):\n",
    "    uploads = []\n",
    "    for i, row in files.iterrows():\n",
    "        accession = row['accession']\n",
    "        uri = '/files/{}/'.format(accession)\n",
    "        obj = server.get_json(uri)\n",
    "        updates = {}\n",
    "        if obj['md5sum'] != row['md5sum']:\n",
    "            print('need to update md5sum', obj['md5sum'])\n",
    "            updates['md5sum'] = row['md5sum']\n",
    "        if obj['submitted_file_name'] != row['submitted_file_name']:\n",
    "            print('need to update filename', obj['submitted_file_name'], row['submitted_file_name'])\n",
    "            updates['submitted_file_name'] = row['submitted_file_name']\n",
    "        if 'file_size' in obj:\n",
    "            if obj['file_size'] != row['file_size:skip']:\n",
    "                print('need to update file_size', obj['file_size'], row['file_size:skip'])\n",
    "                updates['file_size'] = row['file_size:skip']\n",
    "        else:\n",
    "            print(obj['accession'], 'does not have a file_size')\n",
    "            updates['file_size'] = row['file_size:skip']\n",
    "\n",
    "        if len(updates) > 0:\n",
    "            print('updating {} {}'.format(uri, updates))\n",
    "            if not dry_run:\n",
    "                display.display_pretty(server.patch_json(uri, updates))\n",
    "\n",
    "        #upload = server.get_json('/files/{}/upload'.format(row['accession']))\n",
    "        #uploads.append(upload)\n",
    "        #creds = upload['@graph'][0]['upload_credentials']\n",
    "\n",
    "        #if 'myoblast' in row['submitted_file_name']:\n",
    "        #    print(row['submitted_file_name'],creds)\n",
    "        #    run_aws_cp(row['submitted_file_name'], creds)\n",
    "fix_files(files, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython import display\n",
    "display.display_pretty({'a':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCFF382URM Fastq metadata-specified file size 118584 doesn’t match the calculated file size 119013\n",
      "     10T_half_biorep1.bigBed\n",
      "ENCFF136WLJ Fastq metadata-specified file size 111873 doesn’t match the calculated file size 112101\n",
      "     10T_half_biorep2.bigBed\n",
      "ENCFF230XUM Fastq metadata-specified file size 118915 doesn’t match the calculated file size 119343\n",
      "     10T_half_mock_diff_biorep1.bigBed\n",
      "ENCFF378ULY Fastq metadata-specified file size 111634 doesn’t match the calculated file size 111884\n",
      "     10T_half_mock_diff_biorep2.bigBed\n",
      "ENCFF321IHA Fastq file metadata-specified md5sum 19b8e6b76cba2a782db6025430a240da  does not match the calculated md5sum 19b8e6b76cba2a782db6025430a240da\n",
      "     c2c12_myoblast_biorep1.bed.gz\n",
      "ENCFF556RDS Fastq metadata-specified file size 119900 doesn’t match the calculated file size 120266\n",
      "     c2c12_myoblast_biorep1.bigBed\n",
      "ENCFF451IMU Fastq metadata-specified file size 112542 doesn’t match the calculated file size 112822\n",
      "     c2c12_myoblast_biorep2.bigBed\n"
     ]
    }
   ],
   "source": [
    "def review_errors(files):\n",
    "    for i, row in files.iterrows():\n",
    "        accession = row['accession']\n",
    "        uri = '/files/{}/'.format(accession)\n",
    "        obj = server.get_json(uri)\n",
    "\n",
    "        if 'content_error_detail' in obj:\n",
    "            print(accession, obj['content_error_detail'])\n",
    "            print('    ', obj['submitted_file_name'])\n",
    "\n",
    "review_errors(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'19b8e6b76cba2a782db6025430a240da' == '19b8e6b76cba2a782db6025430a240da'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-12-f58610c5bee2>\u001b[0m(14)\u001b[0;36mfix_files\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     12 \u001b[0;31m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'need to update filename'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'submitted_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'submitted_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     13 \u001b[0;31m            \u001b[0mupdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'submitted_file_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'submitted_file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 14 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_size:skip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     15 \u001b[0;31m            \u001b[0mupdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_size:skip'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> p obj\n",
      "{'lab': {'schema_version': '3', '@type': ['Lab', 'Item'], 'country': 'USA', 'fax': '', 'title': 'Barbara Wold, Caltech', 'address2': '1200 California Blvd; MC156-29', 'pi': '/users/0598c868-0b4a-4c5b-9112-8f85c5de5374/', 'postal_code': '91125', 'awards': ['/awards/U54HG006998/', '/awards/UM1HG009443/'], 'name': 'barbara-wold', 'city': 'Pasadena', 'institute_label': 'Caltech', 'state': 'CA', 'status': 'current', 'phone1': '626-395-4916', '@id': '/labs/barbara-wold/', 'phone2': '626-395-4923', 'institute_name': 'California Institute of Technology', 'address1': 'Department of Biochemistry and Molecular Biophysics', 'uuid': '72d5666a-a361-4f7b-ab66-a88e11280937'}, 'biological_replicates': [], 'md5sum': '19b8e6b76cba2a782db6025430a240da ', 'title': 'ENCFF321IHA', 'technical_replicates': [], 'submitted_by': {'@type': ['User', 'Item'], '@id': '/users/bc5b62f7-ce28-4a1e-b6b3-81c9c5a86d7a/', 'title': 'Diane Trout', 'lab': '/labs/barbara-wold/', 'uuid': 'bc5b62f7-ce28-4a1e-b6b3-81c9c5a86d7a'}, 'file_format_type': 'bed9+', 'file_type': 'bed bed9+', 'alternate_accessions': [], 'status': 'content error', 'file_format': 'bed', 'superseded_by': [], 'accession': 'ENCFF321IHA', 'actions': [{'name': 'edit-json', 'title': 'Edit JSON', 'profile': '/profiles/File.json', 'href': '/files/ENCFF321IHA/#!edit-json'}, {'name': 'edit', 'title': 'Edit', 'profile': '/profiles/File.json', 'href': '/files/ENCFF321IHA/#!edit'}], 'aliases': [], 'uuid': '57087728-bdaa-4629-acd4-21a25cdddf5b', 'href': '/files/ENCFF321IHA/@@download/ENCFF321IHA.bed.gz', 'schema_version': '9', '@type': ['File', 'Item'], 'date_created': '2017-01-31T21:44:59.404720+00:00', 'quality_metrics': [], 'flowcell_details': [], '@context': '/terms/', 'output_type': 'candidate enhancers', 'award': {'description': 'The goal of the ENCODE Project is to provide the biomedical community with a complete and biologically interpretable annotation of the human genome. This means discovering and mapping all parts of all genes, including exons, introns, promoters and cis-regulatory sequences, in previous phases of the ENCODE Project, the applicants of this proposal developed and applied robust, high-throughput, genome-wide methods for determining transcription factor occupancy, assessing DNA methylation, identifying RNA transcripts, and experimentally testing candidate regulatory elements and mutations. The combination of experiences from the previous phases with the resulting technology and analysis platforms and the existing, highly productive infrastructure of the applicants form the basis of this response to NHGRI\\'s RFA-HG-11-024 (\"Expanding the Encyclopedia of DNA Elements (ENCODE) in the Human and Model Organisms\"). This application presents an ambitious proposal to expand the biological dimensions of ENCODE to include essentially all transcription factors for measurements of occupancy and to produce transcriptomes from hundreds of very specific cell types, and even single cells. The specific plan is to: 1) determine genome wide occupancy for all transcription factors and major cofactors with high resolution in two or more cell types; 2) map and quantify all messenger RNA transcripts, microRNAs and other non-ribosomal RNAs in more than 300 well-defined, uncultured cell types; 3) map DNA methylation state genome-wide at nucleotide resolution in more than 300 cell types; and 4) apply a high-throughput transient transfection assay system to test the impact of -2,000 candidate regulatory elements on gene regulation. All experimental work in this project will be evaluated by appropriate quality metrics, and after quality control, all data will be rapidly deposited in publi, freely accessible genome databases. In addition, computational analyses, including evaluation of comparative and population genomics data, will be integrated with the experimental production to help ensure quality and to capture information in forms useful to biologists, genomicists, and medical researchers. Completion of these Specific Aims will enable biomedical researchers to better and more rapidly understand the consequences of mutations in genomic disorders, including cancer, cardiovascular disease, and almost ail common diseases and, therefore, to more fully realize the potential of genomics to impact human health.', 'schema_version': '3', '@type': ['Award', 'Item'], 'rfa': 'ENCODE3', 'title': 'TOWARD A COMPREHENSIVE FUNCTIONAL ANNOTATION OF THE HUMAN GENOME', 'pi': {'@type': ['User', 'Item'], '@id': '/users/a62cfec5-57a0-45ab-b943-8ca0e0057bb6/', 'title': 'Richard Myers', 'lab': {'awards': ['/awards/U54HG006998/', '/awards/U54HG004576/', '/awards/UM1HG009411/'], '@type': ['Lab', 'Item'], 'country': 'USA', 'fax': '256-327-0978', 'schema_version': '3', 'title': 'Richard Myers, HAIB', 'pi': '/users/a62cfec5-57a0-45ab-b943-8ca0e0057bb6/', 'postal_code': '35806', 'state': 'AL', 'name': 'richard-myers', 'city': 'Huntsville', 'institute_label': 'HAIB', 'status': 'current', 'phone1': '256-327-5220', '@id': '/labs/richard-myers/', 'phone2': '', 'institute_name': 'HudsonAlpha Institute for Biotechnology', 'address1': '601 Genome Way', 'uuid': 'c0a3540e-8ef0-4d4d-a449-ae47c2475838'}, 'uuid': 'a62cfec5-57a0-45ab-b943-8ca0e0057bb6'}, 'end_date': '2016-07-31', 'name': 'U54HG006998', 'start_date': '2012-09-21', 'status': 'current', 'viewing_group': 'ENCODE3', 'url': 'http://projectreporter.nih.gov/project_info_details.cfm?aid=8402461', 'project': 'ENCODE', '@id': '/awards/U54HG006998/', 'uuid': '6272092d-f953-4b86-b04b-cad31d64352f'}, 'dataset': '/annotations/ENCSR991QYA/', 'content_error_detail': 'Fastq file metadata-specified md5sum 19b8e6b76cba2a782db6025430a240da  does not match the calculated md5sum 19b8e6b76cba2a782db6025430a240da', 'assembly': 'mm10', 'output_category': 'annotation', 'submitted_file_name': 'c2c12_myoblast_biorep1.bed.gz', '@id': '/files/ENCFF321IHA/', 'audit': {'INTERNAL_ACTION': [{'category': 'inconsistent md5sum', 'name': 'audit_file_md5sum_integrity', 'level_name': 'INTERNAL_ACTION', 'level': 30, 'path': '/files/ENCFF321IHA/', 'detail': 'File /files/ENCFF321IHA/ has an md5sum value of 19b8e6b76cba2a782db6025430a240da , which is not 32 characters long.'}, {'category': 'missing derived_from', 'name': 'audit_file_processed_empty_derived_from', 'level_name': 'INTERNAL_ACTION', 'level': 30, 'path': '/files/ENCFF321IHA/', 'detail': 'derived_from is a list of files that were used to create a given file; for example, fastq file(s) will appear in the derived_from list of an alignments file. Processed file /files/ENCFF321IHA/ is missing the requisite file specification in its derived_from list.'}, {'category': 'missing file_size', 'name': 'audit_file_size', 'level_name': 'INTERNAL_ACTION', 'level': 30, 'path': '/files/ENCFF321IHA/', 'detail': 'File /files/ENCFF321IHA/ requires a value for file_size'}]}, 'fastq_signature': [], 'dbxrefs': []}\n",
      "ipdb> p obj.keys()\n",
      "dict_keys(['lab', 'biological_replicates', 'md5sum', 'title', 'technical_replicates', 'submitted_by', 'file_format_type', 'file_type', 'alternate_accessions', 'status', 'file_format', 'superseded_by', 'accession', 'actions', 'aliases', 'uuid', 'href', 'schema_version', '@type', 'date_created', 'quality_metrics', 'flowcell_details', '@context', 'output_type', 'award', 'dataset', 'content_error_detail', 'assembly', 'output_category', 'submitted_file_name', '@id', 'audit', 'fastq_signature', 'dbxrefs'])\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-004a3aad3af7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/files/{}/upload'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accession'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": [
    "#server.get_json('/files/{}/upload'.format(row['accession']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj['@graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from htsworkflow.submission.aws_submission import run_aws_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in created:\n",
    "    #print(row['submitted_file_name'], row['upload_credentials'])\n",
    "    if not os.path.exists(row['submitted_file_name']):\n",
    "        print('missing', row['submitted_file_name'])\n",
    "    else:\n",
    "        run_aws_cp(row['submitted_file_name'], row['upload_credentials'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if created:\n",
    "    files.to_excel('/tmp/files.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for row in created:\n",
    "    print(row['accession'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Annotations With biorep comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server.patch_json?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Biosamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#y4q1 = gcat.get_file(spreadsheet_name, fmt='pandas_excel')\n",
    "#biosample = y4q1.parse('Biosamples', header=0)\n",
    "#created = server.post_sheet('/biosamples/', biosample, verbose=True, dry_run=True)\n",
    "#print(len(created))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#biosample.to_excel('/dev/shm/biosamples.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y4q1 = gcat.get_file(spreadsheet_name, fmt='pandas_excel')\n",
    "experiments = y4q1.parse('Experiments', header=0)\n",
    "\n",
    "created = server.post_sheet('/experiments/', experiments, verbose=True, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if created:\n",
    "    experiments.to_excel('/tmp/experiments.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y4q1 = gcat.get_file(spreadsheet_name, fmt='pandas_excel')\n",
    "libraries = y4q1.parse('Libraries', header=0)\n",
    "\n",
    "created = server.post_sheet('/libraries/', libraries, verbose=True, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if created:\n",
    "    libraries.to_excel('/tmp/libraries.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y4q1 = gcat.get_file(spreadsheet_name, fmt='pandas_excel')\n",
    "replicates = y4q1.parse('Replicates', header=0)\n",
    "\n",
    "created = server.post_sheet('/replicates/', replicates, verbose=True, dry_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if created:\n",
    "    replicates.to_excel('/tmp/replicates.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

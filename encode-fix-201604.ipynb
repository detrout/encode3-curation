{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Introduction\n",
    "\n",
    "In building the fastq archives I missed copying the L2 files and forgot to uploaded.\n",
    "\n",
    "Them when I built them themerge script ran on systems without access to the flowcell archive on packrat and so I ended up with empty files.\n",
    "\n",
    "I need to resubmit them to the DCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import paramiko\n",
    "import json\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from curation_common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from htsworkflow.util import hashfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encode = ENCODED('www.encodeproject.org')\n",
    "encode.load_netrc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_files = {\n",
    "'16930/16930_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF262CIY/\",\n",
    "'16929/16929_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF500NCE/\",\n",
    "'16954/16954_HLGG7BCXX_c116_l2.fastq.gz': \"/files/ENCFF216NUY/\",\n",
    "'16923/16923_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF700OLU/\",\n",
    "'16924/16924_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF853SOX/\",\n",
    "'16937/16937_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF078SPI/\",\n",
    "'16940/16940_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF509HFH/\",\n",
    "'16939/16939_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF887HOU/\",\n",
    "'16933/16933_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF551UCM/\",\n",
    "'16944/16944_HLGH2BCXX_c116_l2.fastq.gz': \"/files/ENCFF065YUF/\",\n",
    "'16957/16957_HLGG7BCXX_c116_l2.fastq.gz': \"/files/ENCFF198SLH/\",\n",
    "'16950/16950_HLGH2BCXX_c116_l2.fastq.gz': \"/files/ENCFF306XSY/\",\n",
    "'16927/16927_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF160LUK/\",\n",
    "'16949/16949_HLGH2BCXX_c116_l2.fastq.gz': \"/files/ENCFF974EKR/\",\n",
    "'16943/16943_HLGH2BCXX_c116_l2.fastq.gz': \"/files/ENCFF737TKD/\",\n",
    "'16934/16934_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF854WTE/\",\n",
    "'16941/16941_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF267VJG/\",\n",
    "'16936/16936_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF555MUK/\",\n",
    "'16925/16925_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF476UXE/\",\n",
    "'16922/16922_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF294JRP/\",\n",
    "'16955/16955_HLGG7BCXX_c116_l2.fastq.gz': \"/files/ENCFF106HJE/\",\n",
    "'16928/16928_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF063CEM/\",\n",
    "'16931/16931_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF237SXT/\",\n",
    "'16935/16935_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF155LJD/\",\n",
    "'16942/16942_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF277ETM/\",\n",
    "'16948/16948_HLGH2BCXX_c116_l2.fastq.gz': \"/files/ENCFF824LLV/\",\n",
    "'16926/16926_HLHGNBCXX_c116_l2.fastq.gz': \"/files/ENCFF876NSY/\",\n",
    "'16951/16951_HLGG7BCXX_c116_l2.fastq.gz': \"/files/ENCFF301BEB/\",\n",
    "'16956/16956_HLGG7BCXX_c116_l2.fastq.gz': \"/files/ENCFF987HYN/\",\n",
    "'16945/16945_HLGH2BCXX_c116_l2.fastq.gz': \"/files/ENCFF216DGZ/\",\n",
    "'16932/16932_HLGVVBCXX_c116_l2.fastq.gz': \"/files/ENCFF771GDS/\",\n",
    "'16938/16938_HLHJMBCXX_c116_l2.fastq.gz': \"/files/ENCFF286QHA/\",        \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_root = '/woldlab/castor/home/diane/proj/submission/encode-201604'\n",
    "pongo = paramiko.SSHClient()\n",
    "pongo.set_missing_host_key_policy(paramiko.WarningPolicy())\n",
    "pongo.connect('pongo.cacr.caltech.edu', username='diane')\n",
    "sftp = pongo.open_sftp()\n",
    "sftp.chdir(submission_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sftp_exists(sftp, filename):\n",
    "    try:\n",
    "        stat = sftp.stat(filename)\n",
    "    except FileNotFoundError as e:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reupload_credentials(accession):\n",
    "    response = encode.post_json(accession + 'upload', {})\n",
    "    if response.get('status') == 'success':\n",
    "        metadata = response['@graph'][0]\n",
    "        print('creds =', metadata['upload_credentials'])\n",
    "        print(\"run_aws_cp('{}', creds)\".format(metadata['submitted_file_name']))\n",
    "        return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_success(sftp, metadata):\n",
    "    upload_filename = metadata.get('submitted_file_name') + '.upload'\n",
    "    if sftp_exists(sftp, upload_filename):\n",
    "        print('weird {} exists'.format(upload_filename))\n",
    "    else:\n",
    "        upload_file = sftp.open(upload_filename, 'wa')\n",
    "        upload_file.write(json.dumps(metadata, indent=4, sort_keys=True))\n",
    "        upload_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_files = {}\n",
    "for filename in all_files:\n",
    "    upload_filename = filename + '.upload'\n",
    "    if sftp_exists(sftp, upload_filename):\n",
    "        print('{} was uploaded'.format(filename))\n",
    "    else:\n",
    "        bad_files[filename] = all_files[filename]\n",
    "        print('{} was NOT uploaded'.format(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for filename in bad_files:\n",
    "    try:\n",
    "        stat = sftp.stat(filename)\n",
    "        if stat.st_size < 100:\n",
    "            print('{} too small {}'.format(filename, stat.st_size))\n",
    "    except FileNotFoundError as e:\n",
    "        print('{} not found'.format(filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following to refresh upload credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#metadata = reupload_credentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#metadata['submitted_file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#save_success(sftp, metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Need to fix metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = get_model(\n",
    "    'encode', \n",
    "    directory=os.path.expanduser('~/proj/submission/encode-201604/'), \n",
    "    use_contexts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sparql -m model\n",
    "select ?s ?md5\n",
    "where {\n",
    "    ?s <http://jumpgate.caltech.edu/wiki/UcscDaf#md5sum> ?md5 ;\n",
    "       \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upload_files = glob(os.path.expanduser('~/proj/submission/encode-201604/*/*_l2.fastq.gz.upload'))\n",
    "\n",
    "for filename in upload_files:\n",
    "    with open(filename, 'rt') as instream:\n",
    "        body = json.load(instream)\n",
    "        if '@graph' in body:\n",
    "            data = body['@graph'][0]\n",
    "        else:\n",
    "            data = body\n",
    "        for key in ['@id', 'file_size', 'md5sum', 'submitted_file_name']:\n",
    "            print(key, data[key])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "curdir = os.getcwd()\n",
    "os.chdir(os.path.expanduser('~/proj/submission/encode-201604/'))\n",
    "\n",
    "for filename in upload_files:\n",
    "    with open(filename, 'rt') as instream:\n",
    "        body = json.load(instream)\n",
    "        if '@graph' in body:\n",
    "            data = body['@graph'][0]\n",
    "        else:\n",
    "            data = body\n",
    "        \n",
    "        remote_data = encode.get_json(data['@id'])\n",
    "        submitted_file_name = data['submitted_file_name']\n",
    "        md5sum = hashfile.make_md5sum(submitted_file_name)\n",
    "        stat = os.stat(submitted_file_name)\n",
    "        payload = {'file_size': stat.st_size, 'md5sum': md5sum}\n",
    "        do_update = False\n",
    "        \n",
    "        for key in ['md5sum', 'file_size']:\n",
    "            if remote_data[key] != payload[key]:\n",
    "                print(\"Upd: {} {} -> {}\".format(data['@id'], payload[key], remote_data[key]))\n",
    "                do_update = True\n",
    "\n",
    "        if do_update:\n",
    "            result = encode.patch_json(data['@id'], payload)\n",
    "            result_data = result['@graph'][0]\n",
    "            print('Res:', result_data['@id'], result_data['md5sum'], result_data['file_size'])\n",
    "            do_update = False\n",
    "os.chdir(curdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = encode.get_json('/files/ENCFF063CEM/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encode.patch_json?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testmodel = get_model(use_contexts=False)\n",
    "load_jsonld_into_model(testmodel, body['@graph'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sparql -m testmodel\n",
    "select ?s ?p ?o\n",
    "where {\n",
    "    ?s ?p ?o .\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(testmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
